{
    "name": "root",
    "gauges": {
        "Mover.Policy.Entropy.mean": {
            "value": 1.283880352973938,
            "min": 1.283880352973938,
            "max": 1.2938101291656494,
            "count": 42
        },
        "Mover.Policy.Entropy.sum": {
            "value": 38517.6953125,
            "min": 15354.9384765625,
            "max": 40106.0625,
            "count": 42
        },
        "Mover.Environment.EpisodeLength.mean": {
            "value": 321.59139784946234,
            "min": 259.0608695652174,
            "max": 383.28205128205127,
            "count": 42
        },
        "Mover.Environment.EpisodeLength.sum": {
            "value": 29908.0,
            "min": 11784.0,
            "max": 30945.0,
            "count": 42
        },
        "Mover.Step.mean": {
            "value": 4259501.0,
            "min": 3029843.0,
            "max": 4259501.0,
            "count": 42
        },
        "Mover.Step.sum": {
            "value": 4259501.0,
            "min": 3029843.0,
            "max": 4259501.0,
            "count": 42
        },
        "Mover.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.0034000645391643047,
            "min": -0.012598339468240738,
            "max": 0.022690827026963234,
            "count": 42
        },
        "Mover.Policy.ExtrinsicValueEstimate.sum": {
            "value": 0.3162060081958771,
            "min": -0.4031468629837036,
            "max": 2.1783194541931152,
            "count": 42
        },
        "Mover.Environment.CumulativeReward.mean": {
            "value": -0.07864480361502657,
            "min": -0.38817731405679995,
            "max": 0.5061287052648248,
            "count": 42
        },
        "Mover.Environment.CumulativeReward.sum": {
            "value": -7.313966736197472,
            "min": -30.277830496430397,
            "max": 53.64964275807142,
            "count": 42
        },
        "Mover.Policy.ExtrinsicReward.mean": {
            "value": -0.07864480361502657,
            "min": -0.38817731405679995,
            "max": 0.5061287052648248,
            "count": 42
        },
        "Mover.Policy.ExtrinsicReward.sum": {
            "value": -7.313966736197472,
            "min": -30.277830496430397,
            "max": 53.64964275807142,
            "count": 42
        },
        "Mover.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 42
        },
        "Mover.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 42
        },
        "Mover.Losses.PolicyLoss.mean": {
            "value": 0.010531492216978222,
            "min": 0.006351886465563439,
            "max": 0.012195864076784347,
            "count": 41
        },
        "Mover.Losses.PolicyLoss.sum": {
            "value": 0.010531492216978222,
            "min": 0.006351886465563439,
            "max": 0.012195864076784347,
            "count": 41
        },
        "Mover.Losses.ValueLoss.mean": {
            "value": 0.009781513269990683,
            "min": 0.007789828279055655,
            "max": 0.0116107968846336,
            "count": 41
        },
        "Mover.Losses.ValueLoss.sum": {
            "value": 0.009781513269990683,
            "min": 0.007789828279055655,
            "max": 0.0116107968846336,
            "count": 41
        },
        "Mover.Policy.LearningRate.mean": {
            "value": 1.432139372650667e-05,
            "min": 1.432139372650667e-05,
            "max": 1.593435632832e-05,
            "count": 41
        },
        "Mover.Policy.LearningRate.sum": {
            "value": 1.432139372650667e-05,
            "min": 1.432139372650667e-05,
            "max": 1.593435632832e-05,
            "count": 41
        },
        "Mover.Policy.Epsilon.mean": {
            "value": 0.06419658666666667,
            "min": 0.06016416,
            "max": 0.06419658666666667,
            "count": 41
        },
        "Mover.Policy.Epsilon.sum": {
            "value": 0.06419658666666667,
            "min": 0.06016416,
            "max": 0.06419658666666667,
            "count": 41
        },
        "Mover.Policy.Beta.mean": {
            "value": 0.000718907584,
            "min": 0.000718907584,
            "max": 0.000798749632,
            "count": 41
        },
        "Mover.Policy.Beta.sum": {
            "value": 0.000718907584,
            "min": 0.000718907584,
            "max": 0.000798749632,
            "count": 41
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1742863407",
        "python_version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\draco\\AppData\\Local\\Programs\\Python\\Python39\\Scripts\\mlagents-learn ./config/ppo/bullethell.yaml --run-id=move_04 --resume",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1742871955"
    },
    "total": 8548.4409593,
    "count": 1,
    "self": 0.004525399999693036,
    "children": {
        "run_training.setup": {
            "total": 0.13788149999999977,
            "count": 1,
            "self": 0.13788149999999977
        },
        "TrainerController.start_learning": {
            "total": 8548.2985524,
            "count": 1,
            "self": 19.837437899977886,
            "children": {
                "TrainerController._reset_env": {
                    "total": 8.0167096,
                    "count": 1,
                    "self": 8.0167096
                },
                "TrainerController.advance": {
                    "total": 8520.347483000021,
                    "count": 1258750,
                    "self": 19.02912629990169,
                    "children": {
                        "env_step": {
                            "total": 7994.779707800458,
                            "count": 1258750,
                            "self": 5475.559921800599,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 2506.295831200274,
                                    "count": 1258751,
                                    "self": 59.77735519991256,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 2446.5184760003613,
                                            "count": 1258751,
                                            "self": 2446.5184760003613
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 12.923954799584518,
                                    "count": 1258749,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 8438.776477599999,
                                            "count": 1258749,
                                            "is_parallel": true,
                                            "self": 3953.524822999595,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0004919999999994928,
                                                    "count": 2,
                                                    "is_parallel": true,
                                                    "self": 0.00017829999999730006,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0003137000000021928,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.0003137000000021928
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 4485.251162600403,
                                                    "count": 1258749,
                                                    "is_parallel": true,
                                                    "self": 69.65237390052152,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 58.51180140012259,
                                                            "count": 1258749,
                                                            "is_parallel": true,
                                                            "self": 58.51180140012259
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 4174.202901199422,
                                                            "count": 1258749,
                                                            "is_parallel": true,
                                                            "self": 4174.202901199422
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 182.8840861003369,
                                                            "count": 1258749,
                                                            "is_parallel": true,
                                                            "self": 87.45432249985588,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 95.42976360048102,
                                                                    "count": 2517498,
                                                                    "is_parallel": true,
                                                                    "self": 95.42976360048102
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 506.5386488996618,
                            "count": 1258749,
                            "self": 23.20021539919793,
                            "children": {
                                "process_trajectory": {
                                    "total": 52.01620890046314,
                                    "count": 1258749,
                                    "self": 51.895299100463205,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.12090979999993579,
                                            "count": 2,
                                            "self": 0.12090979999993579
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 431.3222246000007,
                                    "count": 41,
                                    "self": 344.03588170000756,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 87.28634289999314,
                                            "count": 1640,
                                            "self": 87.28634289999314
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.09692189999987022,
                    "count": 1,
                    "self": 0.01759409999976924,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.07932780000010098,
                            "count": 1,
                            "self": 0.07932780000010098
                        }
                    }
                }
            }
        }
    }
}